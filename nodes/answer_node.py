"""
Answer Node
Final yanÄ±tÄ± oluÅŸturur (LLM ile)
"""

from state_schema import ChatState
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

from prompts.role_prompt import get_role_prompt
from prompts.style_guide import get_style_guide
from prompts.context_rules import get_context_rules
from prompts.output_format import get_output_format, build_minimal_system_prompt


def answer_node(state: ChatState, llm: ChatGoogleGenerativeAI) -> ChatState:
    """
    Answer node - final yanÄ±tÄ± oluÅŸturur.
    
    Args:
        state: Current conversation state
        llm: LangChain LLM instance
    
    Returns:
        Updated state with final answer
    """
    intent = state.get("intent", "unknown")
    query = state["user_query"]
    context = state.get("retrieved_context", "")
    active_levels = state.get("active_levels", [])
    
    print(f"\nğŸ’¬ [ANSWER NODE] Final yanÄ±t oluÅŸturuluyor...")
    print(f"   Intent: {intent}")
    
    # Greeting intent - direkt yanÄ±t ver
    if intent == "greeting":
        answer = "Merhaba! Ben Ã‡Ã¶zÃ¼m EÄŸitim KurumlarÄ±'nÄ±n veli asistanÄ±yÄ±m. Size nasÄ±l yardÄ±mcÄ± olabilirim?"
        state["final_answer"] = answer
        print(f"   âœ… Greeting yanÄ±tÄ± oluÅŸturuldu")
        return state
    
    # Unknown intent - fallback
    if intent == "unknown":
        answer = "ÃœzgÃ¼nÃ¼m, sorunuzu tam olarak anlayamadÄ±m. EÄŸitim programlarÄ±, etkinlikler veya okul hakkÄ±nda baÅŸka bir ÅŸey sormak ister misiniz?"
        state["final_answer"] = answer
        print(f"   âš ï¸  Unknown intent - fallback yanÄ±t")
        return state
    
    # Price intent - contact info
    if intent == "price":
        answer = """Ãœcret bilgileri iÃ§in lÃ¼tfen okul iletiÅŸim kanallarÄ±mÄ±zdan bizimle irtibata geÃ§in:

ğŸ“ **Telefon:** [okul telefonu]
ğŸ“§ **E-posta:** [okul email]
ğŸŒ **Website:** [okul website]

KayÄ±t ve Ã¼cret konusundaki tÃ¼m detaylarÄ± size aktaracaklardÄ±r."""
        state["final_answer"] = answer
        print(f"   ğŸ’° Price inquiry - contact info verildi")
        return state
    
    # Education/Event intents - LLM ile yanÄ±t oluÅŸtur
    active_levels_str = ", ".join(active_levels).title() if active_levels else "TÃ¼m kademeler"
    
    # Build minimal system prompt (context OLMADAN - multi-turn iÃ§in)
    minimal_system_prompt = build_minimal_system_prompt(
        role_prompt=get_role_prompt(),
        style_guide=get_style_guide(),
        context_rules=get_context_rules(),
        output_format=get_output_format(),
        active_levels=active_levels_str
    )
    
    # Get conversation history (sliding window)
    messages = state.get("messages", [])
    recent_messages = messages[-10:] if len(messages) > 10 else messages  # Last 10 messages
    
    # Build messages for LLM - Context'i SON mesajdan Ã–NCE ekle!
    # Bu sayede context SADECE son soruyla iliÅŸkilendirilir
    if len(recent_messages) > 0:
        last_human_message = recent_messages[-1]
        conversation_history = recent_messages[:-1]
    else:
        last_human_message = HumanMessage(content=query)
        conversation_history = []
    
    llm_messages = [
        SystemMessage(content=minimal_system_prompt),      # Rol & kurallar (context YOK!)
        *conversation_history,                             # Eski conversation (context'ler YOK!)
        AIMessage(content=f"""Ä°ÅŸte sorunuzla ilgili bulduÄŸum bilgiler:

{context}"""),  # â† Context: Assistant'Ä±n referans bilgisi (LangChain pattern)
        last_human_message                                 # KullanÄ±cÄ±nÄ±n son sorusu
    ]
    
    print(f"   ğŸ“ LLM'e gÃ¶nderilen mesaj sayÄ±sÄ±: {len(llm_messages)} (sliding window + context injection)")
    
    # Generate answer
    response = llm.invoke(llm_messages)
    answer = response.content if isinstance(response.content, str) else str(response.content)
    
    # Update state
    state["final_answer"] = answer
    
    print(f"   âœ… Final yanÄ±t oluÅŸturuldu ({len(answer)} karakter)")
    
    return state


def direct_answer_node(state: ChatState, llm: ChatGoogleGenerativeAI) -> ChatState:
    """
    Direct answer node - context olmadan direkt yanÄ±t ver (greeting, unknown).
    
    Bu node retrieve yapmadan direkt yanÄ±t Ã¼retir.
    """
    return answer_node(state, llm)


def search_news_node(state: ChatState) -> ChatState:
    """
    Search news node - okul haberleri ve etkinlikler (placeholder).
    
    TODO: GerÃ§ek web scraping veya API entegrasyonu eklenecek.
    """
    print(f"\nğŸ“° [SEARCH NEWS NODE] Haber/etkinlik arama (placeholder)")
    
    # Placeholder response
    state["retrieved_context"] = "ğŸš§ Haber ve etkinlik arama Ã¶zelliÄŸi henÃ¼z aktif deÄŸil."
    
    return state


def price_info_node(state: ChatState) -> ChatState:
    """
    Price info node - Ã¼cret bilgileri iÃ§in iletiÅŸim yÃ¶nlendirmesi.
    
    Ãœcret sorularÄ± iÃ§in direkt contact info verir.
    """
    print(f"\nğŸ’° [PRICE INFO NODE] Ãœcret sorgusu - contact info hazÄ±rlanÄ±yor")
    
    # No context needed - answer_node will handle
    state["retrieved_context"] = "Price inquiry - contact info"
    
    return state
