"""
Answer Node
Final yanÄ±tÄ± oluÅŸturur (LLM ile)
"""

from state_schema import ChatState
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

from prompts.role_prompt import get_role_prompt
from prompts.style_guide import get_style_guide
from prompts.context_rules import get_context_rules
from prompts.output_format import get_output_format, build_minimal_system_prompt
import json


def format_news_context(context: str) -> str:
    """
    Event intent iÃ§in context'i Markdown formatÄ±nda dÃ¼zenle.
    GÃ¶rseller ve kaynak linklerini ekle.
    
    Args:
        context: JSON string (news_search_node'dan gelen)
    
    Returns:
        Markdown formatÄ±nda dÃ¼zenlenmiÅŸ context
    """
    try:
        news_items = json.loads(context)
        
        formatted = "**DUYURULAR VE ETKÄ°NLÄ°KLER:**\n\n"
        
        for i, item in enumerate(news_items, 1):
            formatted += f"### {i}. {item['title']}\n\n"
            
            # GÃ¶rsel varsa ekle
            if item.get('image'):
                formatted += f"![{item['title']}]({item['image']})\n\n"
            
            # Ä°Ã§erik
            content = item.get('content') or item.get('summary', '')
            if content:
                formatted += f"{content}\n\n"
            
            # Tarih ve kaynak
            formatted += f"ğŸ“… **Tarih:** {item.get('date', 'Tarih belirtilmemiÅŸ')}\n"
            
            if item.get('url'):
                formatted += f"ğŸ”— **Kaynak:** [{item['url']}]({item['url']})\n"
            
            formatted += "\n---\n\n"
        
        return formatted
        
    except json.JSONDecodeError:
        # JSON deÄŸilse olduÄŸu gibi dÃ¶n
        return context


def answer_node(state: ChatState, llm: ChatGoogleGenerativeAI) -> ChatState:
    """
    Answer node - final yanÄ±tÄ± oluÅŸturur.
    
    Args:
        state: Current conversation state
        llm: LangChain LLM instance
    
    Returns:
        Updated state with final answer
    """
    intent = state.get("intent", "unknown")
    query = state["user_query"]
    context = state.get("retrieved_context", "")
    active_levels = state.get("active_levels", [])
    
    print(f"\nğŸ’¬ [ANSWER NODE] Final yanÄ±t oluÅŸturuluyor...")
    print(f"   Intent: {intent}")
    
    # Greeting intent - direkt yanÄ±t ver
    if intent == "greeting":
        answer = "Merhaba! Ben Ã‡Ã¶zÃ¼m EÄŸitim KurumlarÄ±'nÄ±n veli asistanÄ±yÄ±m. Size nasÄ±l yardÄ±mcÄ± olabilirim?"
        state["final_answer"] = answer
        print(f"   âœ… Greeting yanÄ±tÄ± oluÅŸturuldu")
        return state
    
    # Unknown intent - fallback
    if intent == "unknown":
        answer = "ÃœzgÃ¼nÃ¼m, sorunuzu tam olarak anlayamadÄ±m. EÄŸitim programlarÄ±, etkinlikler veya okul hakkÄ±nda baÅŸka bir ÅŸey sormak ister misiniz?"
        state["final_answer"] = answer
        print(f"   âš ï¸  Unknown intent - fallback yanÄ±t")
        return state
    
    # Price intent - contact info
    if intent == "price":
        answer = """Ãœcret bilgileri iÃ§in lÃ¼tfen okul iletiÅŸim kanallarÄ±mÄ±zdan bizimle irtibata geÃ§in:

ğŸ“ **Telefon:** [okul telefonu]
ğŸ“§ **E-posta:** [okul email]
ğŸŒ **Website:** [okul website]

KayÄ±t ve Ã¼cret konusundaki tÃ¼m detaylarÄ± size aktaracaklardÄ±r."""
        state["final_answer"] = answer
        print(f"   ğŸ’° Price inquiry - contact info verildi")
        return state
    
    # Education/Event intents - LLM ile yanÄ±t oluÅŸtur
    active_levels_str = ", ".join(active_levels).title() if active_levels else "TÃ¼m kademeler"
    
    # Build minimal system prompt (context OLMADAN - multi-turn iÃ§in)
    minimal_system_prompt = build_minimal_system_prompt(
        role_prompt=get_role_prompt(),
        style_guide=get_style_guide(),
        context_rules=get_context_rules(),
        output_format=get_output_format(),
        active_levels=active_levels_str
    )
    
    # Get conversation history (sliding window)
    messages = state.get("messages", [])
    recent_messages = messages[-10:] if len(messages) > 10 else messages  # Last 10 messages
    
    # Build messages for LLM - Context'i SON mesajdan Ã–NCE ekle!
    # Bu sayede context SADECE son soruyla iliÅŸkilendirilir
    if len(recent_messages) > 0:
        last_human_message = recent_messages[-1]
        conversation_history = recent_messages[:-1]
    else:
        last_human_message = HumanMessage(content=query)
        conversation_history = []
    
    # Eski context mesajlarÄ±nÄ± filtrele (clean conversation history)
    # Context injection iÃ§in kullanÄ±lan "Ä°ÅŸte sorunuzla ilgili bulduÄŸum bilgiler:" mesajlarÄ±nÄ± Ã§Ä±kar
    filtered_history = []
    for msg in conversation_history:
        # AIMessage iÃ§inde context injection varsa atla
        if isinstance(msg, AIMessage) and "Ä°ÅŸte sorunuzla ilgili bulduÄŸum bilgiler:" in msg.content:
            continue
        # HumanMessage iÃ§inde context varsa atla (eski yÃ¶ntem iÃ§in backward compatibility)
        if isinstance(msg, HumanMessage) and "### BAÄLAM:" in msg.content:
            continue
        filtered_history.append(msg)
    
    # Event intent iÃ§in context'i format'la (gÃ¶rseller + kaynaklar ekle)
    if intent == "event":
        formatted_context = format_news_context(context)
    else:
        formatted_context = context
    
    # Context'i HumanMessage olarak ekle (daha doÄŸal flow)
    llm_messages = [
        SystemMessage(content=minimal_system_prompt),      # Rol & kurallar (context YOK!)
        *filtered_history,                                 # Temiz conversation history (context'siz)
        HumanMessage(content=f"""### BAÄLAM:
{formatted_context}

### SORU:
{query}"""),  # â† Context + Soru birlikte (HumanMessage olarak)
    ]
    
    print(f"   ğŸ“ LLM'e gÃ¶nderilen mesaj sayÄ±sÄ±: {len(llm_messages)} (sliding window + context injection)")
    
    # Generate answer
    response = llm.invoke(llm_messages)
    answer = response.content if isinstance(response.content, str) else str(response.content)
    
    # Update state
    state["final_answer"] = answer
    
    print(f"   âœ… Final yanÄ±t oluÅŸturuldu ({len(answer)} karakter)")
    
    return state


def direct_answer_node(state: ChatState, llm: ChatGoogleGenerativeAI) -> ChatState:
    """
    Direct answer node - context olmadan direkt yanÄ±t ver (greeting, unknown).
    
    Bu node retrieve yapmadan direkt yanÄ±t Ã¼retir.
    """
    return answer_node(state, llm)


def search_news_node(state: ChatState) -> ChatState:
    """
    Search news node - okul haberleri ve etkinlikler (placeholder).
    
    TODO: GerÃ§ek web scraping veya API entegrasyonu eklenecek.
    """
    print(f"\nğŸ“° [SEARCH NEWS NODE] Haber/etkinlik arama (placeholder)")
    
    # Placeholder response
    state["retrieved_context"] = "ğŸš§ Haber ve etkinlik arama Ã¶zelliÄŸi henÃ¼z aktif deÄŸil."
    
    return state


def price_info_node(state: ChatState) -> ChatState:
    """
    Price info node - Ã¼cret bilgileri iÃ§in iletiÅŸim yÃ¶nlendirmesi.
    
    Ãœcret sorularÄ± iÃ§in direkt contact info verir.
    """
    print(f"\nğŸ’° [PRICE INFO NODE] Ãœcret sorgusu - contact info hazÄ±rlanÄ±yor")
    
    # No context needed - answer_node will handle
    state["retrieved_context"] = "Price inquiry - contact info"
    
    return state
