"""
Context Compression Node
Retrieved dokÃ¼manlarÄ± sÄ±kÄ±ÅŸtÄ±rarak token kullanÄ±mÄ±nÄ± azaltÄ±r
"""

from state_schema import ChatState
from typing import List, Tuple
import re


def compress_chunk(content: str, max_sentences: int = 3) -> str:
    """
    Bir chunk'Ä± sÄ±kÄ±ÅŸtÄ±rÄ±r - en Ã¶nemli 2-3 cÃ¼mleyi tutar.
    
    Strategy:
    1. CÃ¼mlelere ayÄ±r
    2. Ä°lk cÃ¼mle (genelde Ã¶zet) + son 1-2 cÃ¼mle (detay)
    3. Gereksiz ifadeleri temizle
    
    Args:
        content: Orijinal chunk iÃ§eriÄŸi
        max_sentences: Maksimum cÃ¼mle sayÄ±sÄ±
    
    Returns:
        SÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ iÃ§erik
    """
    # CÃ¼mlelere ayÄ±r (. ! ? ile biten)
    sentences = re.split(r'[.!?]\s+', content.strip())
    sentences = [s.strip() for s in sentences if s.strip()]
    
    if len(sentences) <= max_sentences:
        return content
    
    # Ä°lk cÃ¼mle + son 2 cÃ¼mle al (genelde en Ã¶nemli bilgiler)
    compressed = [sentences[0]]  # Ä°lk cÃ¼mle (Ã¶zet)
    
    if len(sentences) > 2:
        compressed.extend(sentences[-(max_sentences-1):])  # Son N-1 cÃ¼mle
    
    # BirleÅŸtir
    result = ". ".join(compressed)
    if not result.endswith('.'):
        result += "."
    
    return result


def semantic_reduce_context(context: str, max_chunks: int = 3) -> str:
    """
    Context'i semantik olarak sÄ±kÄ±ÅŸtÄ±rÄ±r.
    
    Strategy:
    1. Her dokÃ¼manÄ± ayrÄ± chunk olarak iÅŸle
    2. Her chunk'tan en Ã¶nemli 2-3 cÃ¼mleyi al
    3. Maksimum 3 chunk tut (en yÃ¼ksek score'lular)
    
    Args:
        context: Retrieve node'dan gelen full context
        max_chunks: Maksimum chunk sayÄ±sÄ±
    
    Returns:
        SÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ context
    """
    if not context or "Bilgi bulunamadÄ±" in context:
        return context
    
    # Context'i chunk'lara ayÄ±r (--- separator)
    chunks = context.split("\n\n---\n\n")
    
    if len(chunks) <= max_chunks:
        # Zaten az, sadece her chunk'Ä± sÄ±kÄ±ÅŸtÄ±r
        compressed_chunks = []
        for chunk in chunks:
            # BaÅŸlÄ±ÄŸÄ± ayÄ±r
            lines = chunk.split("\n", 1)
            if len(lines) == 2:
                header, content = lines
                compressed_content = compress_chunk(content, max_sentences=3)
                compressed_chunks.append(f"{header}\n{compressed_content}")
            else:
                compressed_chunks.append(chunk)
        
        return "\n\n---\n\n".join(compressed_chunks)
    
    # Ã‡ok fazla chunk var - sadece ilk N'i al (FAISS zaten score'a gÃ¶re sÄ±ralamÄ±ÅŸ)
    selected_chunks = chunks[:max_chunks]
    
    compressed_chunks = []
    for chunk in selected_chunks:
        lines = chunk.split("\n", 1)
        if len(lines) == 2:
            header, content = lines
            compressed_content = compress_chunk(content, max_sentences=3)
            compressed_chunks.append(f"{header}\n{compressed_content}")
        else:
            compressed_chunks.append(chunk)
    
    return "\n\n---\n\n".join(compressed_chunks)


def context_compression_node(state: ChatState) -> ChatState:
    """
    Retrieved context'i sÄ±kÄ±ÅŸtÄ±rÄ±r - token kullanÄ±mÄ±nÄ± azaltÄ±r.
    
    âš ï¸ COMPRESSION CONTROL:
    - state["compress_context"] = True â†’ Compress (default)
    - state["compress_context"] = False â†’ Skip compression (A/B test iÃ§in)
    
    Strategy:
    1. Max 3 chunk al (en alakalÄ± olanlar)
    2. Her chunk'tan en Ã¶nemli 2-3 cÃ¼mle al
    3. Gereksiz tekrarlarÄ± temizle
    
    Target: 60-70% token reduction
    """
    context = state.get("retrieved_context", "")
    
    if not context:
        return state
    
    # ğŸ›ï¸ COMPRESSION SWITCH - A/B test iÃ§in
    if not state.get("compress_context", True):
        print("ğŸ”“ [COMPRESSION NODE] SKIP: compress_context=False (full context mode)")
        return state
    
    print(f"ğŸ—œï¸  [COMPRESSION NODE] Context sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±yor...")
    
    # Orijinal metrikleri hesapla
    original_words = len(context.split())
    original_chars = len(context)
    
    # SÄ±kÄ±ÅŸtÄ±r
    compressed_context = semantic_reduce_context(context, max_chunks=3)
    
    # Yeni metrikleri hesapla
    compressed_words = len(compressed_context.split())
    compressed_chars = len(compressed_context)
    
    # Reduction oranÄ±
    word_reduction = ((original_words - compressed_words) / original_words * 100) if original_words > 0 else 0
    
    print(f"   Orijinal: {original_words} kelime, {original_chars} karakter")
    print(f"   SÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ: {compressed_words} kelime, {compressed_chars} karakter")
    print(f"   ğŸ“‰ Reduction: {word_reduction:.1f}%")
    
    # Update state
    state["retrieved_context"] = compressed_context
    
    return state


# Test
if __name__ == "__main__":
    """Test context compression"""
    
    # Mock context (4 chunks)
    test_context = """**[ANAOKULU] Ä°ngilizce EÄŸitimi**
Anaokulumuzda Ä°ngilizce eÄŸitimi Cambridge programÄ± ile verilmektedir. Haftada 12 saat Main Course ve 2 saat Think&Talk dersi bulunmaktadÄ±r. Native speaker Ã¶ÄŸretmenler eÅŸliÄŸinde eÄŸitim verilir. BookR dijital platform kullanÄ±lmaktadÄ±r. Dil duÅŸu yÃ¶ntemi uygulanmaktadÄ±r.

---

**[ANAOKULU] Spor Faaliyetleri**
Anaokulumuzda Ã§ocuklarÄ±n fiziksel geliÅŸimini desteklemek amacÄ±yla Ã§eÅŸitli spor aktiviteleri dÃ¼zenlenmektedir. Hareket oyunlarÄ±, koordinasyon Ã§alÄ±ÅŸmalarÄ±, ritim aktiviteleri yapÄ±lmaktadÄ±r. Haftada 3 saat beden eÄŸitimi dersi vardÄ±r. Profesyonel spor eÄŸitmenleri gÃ¶rev almaktadÄ±r.

---

**[ANAOKULU] Sanat AtÃ¶lyeleri**
GÃ¶rsel sanatlar eÄŸitimi kapsamÄ±nda resim, heykel, kolaj Ã§alÄ±ÅŸmalarÄ± yapÄ±lmaktadÄ±r. Ã‡ocuklarÄ±n yaratÄ±cÄ±lÄ±ÄŸÄ±nÄ± geliÅŸtiren projeler uygulanÄ±r. MÃ¼zik atÃ¶lyeleri mevcuttur. Orff Ã§algÄ±larÄ± kullanÄ±lmaktadÄ±r.

---

**[ANAOKULU] EDUxLab ProgramÄ±**
EDUxLab atÃ¶lyeleri haftada 2 saat olarak uygulanmaktadÄ±r. Proje tabanlÄ± Ã¶ÄŸrenme yaklaÅŸÄ±mÄ± benimsenir. STEM eÄŸitimi verilir. Robotik kodlama dersleri mevcuttur."""
    
    # Create mock state
    mock_state = ChatState(
        messages=[],
        user_query="Anaokulu programÄ± nedir?",
        intent="education",
        intent_confidence=0.95,
        intent_reasoning="Test",
        active_levels=["anaokulu"],
        retrieved_context=test_context,
        final_answer=None,
        error=None
    )
    
    print("="*80)
    print("ğŸ§ª CONTEXT COMPRESSION TEST")
    print("="*80)
    
    # Compress
    result_state = context_compression_node(mock_state)
    
    print("\nğŸ“„ COMPRESSED CONTEXT:")
    print("="*80)
    print(result_state["retrieved_context"])
    print("="*80)
