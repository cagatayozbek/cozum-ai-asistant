import os
from typing import Annotated, TypedDict
from dotenv import load_dotenv
from operator import add

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage

from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver

from retriever import get_retrieved_documents, SUPPORTED_LEVELS

# --- CONFIGURATION ---
CHAT_MODEL = "gemini-2.5-flash"

# --- STATE SCHEMA (TypedDict for LangGraph) ---
class ChatState(TypedDict):
    """State for the chat graph."""
    levels: list[str] | None
    messages: Annotated[list[BaseMessage], add]  # add operator appends messages
    context: str

def initialize_chat_model() -> ChatGoogleGenerativeAI:
    """API anahtarÄ±nÄ± yÃ¼kler ve sohbet modelini baÅŸlatÄ±r."""
    load_dotenv()
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        raise ValueError("GOOGLE_API_KEY ortam deÄŸiÅŸkeni bulunamadÄ±. .env dosyasÄ±nÄ± kontrol edin.")
    
    return ChatGoogleGenerativeAI(
        model=CHAT_MODEL,
        google_api_key=google_api_key,
        
    )

def format_context(documents: list) -> str:
    """AlÄ±nan dokÃ¼manlarÄ± LLM'e verilecek tek bir metin bloÄŸu haline getirir."""
    if not documents:
        return "Bilgi bulunamadÄ±."
    
    context = []
    for i, (doc, score) in enumerate(documents, 1):
        level = doc.metadata.get('level', 'N/A').upper()
        title = doc.metadata.get('title', 'BaÅŸlÄ±k yok')
        content = doc.metadata.get('original_content', doc.page_content)
        context.append(f"[{level}] {title}\n{content}")
    return "\n\n---\n\n".join(context)

def get_level_display_name(level: str) -> str:
    """Seviye kodunu kullanÄ±cÄ± dostu isme Ã§evirir."""
    mapping = {
        "anaokulu": "Anaokulu",
        "ilkokul": "Ä°lkokul (1-4. SÄ±nÄ±f)",
        "ortaokul": "Ortaokul (5-8. SÄ±nÄ±f)",
        "lise": "Lise (9-12. SÄ±nÄ±f)"
    }
    return mapping.get(level, level)

def welcome_and_get_levels() -> list:
    """Veliyi karÅŸÄ±lar ve Ã§ocuklarÄ±nÄ±n eÄŸitim kademelerini Ã¶ÄŸrenir."""
    print("\n" + "="*70)
    print("ğŸ“ Ã‡Ã¶zÃ¼m EÄŸitim KurumlarÄ± - AI Veli AsistanÄ±")
    print("="*70)
    print("\nMerhaba! Ben Ã‡Ã¶zÃ¼m Koleji AI asistanÄ±yÄ±m.")
    print("Size okulumuz hakkÄ±nda bilgi vermek iÃ§in buradayÄ±m. ğŸ˜Š\n")
    
    # Seviye seÃ§imi
    print("LÃ¼tfen Ã§ocuÄŸunuzun/Ã§ocuklarÄ±nÄ±zÄ±n eÄŸitim kademesini seÃ§in:")
    print("(Birden fazla Ã§ocuÄŸunuz varsa, virgÃ¼lle ayÄ±rarak girebilirsiniz)\n")
    
    for i, level in enumerate(SUPPORTED_LEVELS, 1):
        print(f"{i}. {get_level_display_name(level)}")
    print(f"{len(SUPPORTED_LEVELS) + 1}. TÃ¼m kademeler")
    
    while True:
        choice = input("\nSeÃ§iminiz (Ã¶rn: 1,2 veya 1): ").strip()
        
        if not choice:
            print("âŒ LÃ¼tfen bir seÃ§im yapÄ±n.")
            continue
        
        # "TÃ¼m kademeler" seÃ§eneÄŸi
        if choice == str(len(SUPPORTED_LEVELS) + 1):
            return SUPPORTED_LEVELS
        
        # Birden fazla seÃ§im
        try:
            choices = [int(c.strip()) for c in choice.split(',')]
            selected_levels = []
            
            for c in choices:
                if 1 <= c <= len(SUPPORTED_LEVELS):
                    selected_levels.append(SUPPORTED_LEVELS[c - 1])
                else:
                    print(f"âŒ GeÃ§ersiz seÃ§im: {c}")
                    break
            else:
                if selected_levels:
                    print("\nâœ… SeÃ§ilen kademeler:")
                    for level in selected_levels:
                        print(f"   â€¢ {get_level_display_name(level)}")
                    print("\nArtÄ±k bu kademelere Ã¶zel sorular sorabilirsiniz!")
                    return selected_levels
        except ValueError:
            print("âŒ LÃ¼tfen geÃ§erli sayÄ±lar girin (Ã¶rn: 1,2 veya 3)")

def show_help():
    """YardÄ±m mesajÄ±nÄ± gÃ¶sterir."""
    print("\n" + "â”€"*70)
    print("ğŸ“ Komutlar:")
    print("â”€"*70)
    print("  /help veya /yardim    - Bu yardÄ±m mesajÄ±nÄ± gÃ¶sterir")
    print("  /seviye veya /kademe  - EÄŸitim kademesini deÄŸiÅŸtirir")
    print("  /temizle veya /clear  - Sohbet geÃ§miÅŸini temizler")
    print("  /cikis veya /exit     - Programdan Ã§Ä±kar")
    print("â”€"*70)

# --- GRAPH NODES ---
def retrieve_node(state: ChatState) -> dict:
    """Retrieve relevant documents based on last user message."""
    if not state.get("messages"):
        return {"context": ""}  # Return default empty context
    
    # Get last user message
    last_user_msg = None
    for msg in reversed(state["messages"]):
        if isinstance(msg, HumanMessage):
            last_user_msg = msg.content
            break
    
    if not last_user_msg or not state.get("levels"):
        return {"context": ""}
    
    # Retrieve documents
    retrieved_docs = get_retrieved_documents(
        last_user_msg,
        k=4,
        levels=state.get("levels", []),
        force_recreate=False,
        silent=True
    )
    
    # Format context
    if not retrieved_docs:
        context = "Bilgi bulunamadÄ±."
    else:
        context_parts = []
        for i, (doc, score) in enumerate(retrieved_docs, 1):
            level = doc.metadata.get('level', 'N/A').upper()
            title = doc.metadata.get('title', 'BaÅŸlÄ±k yok')
            content = doc.metadata.get('original_content', doc.page_content)
            context_parts.append(f"[{level}] {title}\n{content}")
        context = "\n\n---\n\n".join(context_parts)
    
    # Return context to be used by LLM (store in state for next node)
    # Don't add to messages, just pass it through state
    return {"context": context}

def llm_node(state: ChatState, llm: ChatGoogleGenerativeAI) -> dict:
    """Generate response using LLM with context."""
    if not state.get("messages"):
        return {}
    
    # Get last user message
    user_msg = None
    for msg in reversed(state["messages"]):
        if isinstance(msg, HumanMessage):
            user_msg = msg.content
            break
    
    if not user_msg:
        return {}
    
    # Get context from state (set by retrieve_node)
    context = state.get("context", "Bilgi bulunamadÄ±.")
    
    # Build system prompt
    level_info = ", ".join([get_level_display_name(l) for l in state.get("levels", [])]) if state.get("levels") else "HenÃ¼z seÃ§ilmedi"
    
    system_prompt = f"""Sen Ã‡Ã¶zÃ¼m EÄŸitim KurumlarÄ± iÃ§in tasarlanmÄ±ÅŸ yapay zeka destekli bir veli asistanÄ±sÄ±n.
GÃ¶revin: Velilere okul hakkÄ±nda doÄŸru, net ve samimi bilgi vermek.

KURALLAR:
1. YanÄ±tlarÄ±nÄ± SADECE saÄŸlanan BAÄLAM'daki bilgilere dayandÄ±r
2. YanÄ±tlarÄ±nda KESÄ°NLÄ°KLE uydurma yapma
3. Asla tahmin etme veya uydurma
4. Profesyonel ve samimi bir Ã¼slup kullan

6. KullanÄ±cÄ±ya hitap ederken: "siz", "sizlere", "istiyorsanÄ±z" gibi saygÄ±lÄ± ifadeler
7. YanÄ±tlarÄ± 2-5 cÃ¼mle ile sÄ±nÄ±rla, Ã¶zet ver


ÅU ANDA SEÃ‡Ä°LÄ° KADEMELER: {level_info}

GENEL SORULAR Ä°Ã‡Ä°N REHBERLÄ°K:
- EÄŸer soru Ã‡OK GENEL ise (Ã¶rn: "okul hakkÄ±nda bilgi", "okulunuzu anlatÄ±r mÄ±sÄ±nÄ±z"):
  â†’ BAÄLAM'dan 1-2 ilginÃ§ bilgi ver (Ã¶rn: eÄŸitim anlayÄ±ÅŸÄ±, Ã¶zellikler)
  â†’ MUTLAKA bu listeyi gÃ¶ster:
  
  "Size daha detaylÄ± hangi konuda bilgi verebilirim?
  â€¢ EÄŸitim programlarÄ± ve mÃ¼fredat
  â€¢ Ä°ngilizce ve yabancÄ± dil eÄŸitimi  
  â€¢ Sosyal aktiviteler ve kulÃ¼pler
  â€¢ Ãœcretler ve kayÄ±t iÅŸlemleri
  â€¢ Servis ve yemek hizmetleri"

KADEME YÃ–NETÄ°MÄ°:
- EÄŸer kullanÄ±cÄ± seÃ§ili OLMAYAN bir kademe hakkÄ±nda soru sorarsa:
  â†’ Kibarca sor: "Åu an {level_info} iÃ§in bilgi verebiliyorum. [Ä°stenenKademe] hakkÄ±nda da bilgi almak ister misiniz?"
- KullanÄ±cÄ± EVET derse â†’ "Harika! [Ä°stenenKademe] bilgilerini de ekledim. Sorunuzu tekrar sorabilirsiniz." de
  VE `#KADEME_EKLE:[kademe_adi]#` tag'i ekle (kullanÄ±cÄ± gÃ¶rmez)

Ã–zel Tag FormatÄ±:
- #KADEME_EKLE:anaokulu# â†’ Anaokulu ekle
- #KADEME_EKLE:lise# â†’ Lise ekle
- Tag'i yanÄ±tÄ±n EN SONUNA ekle, kullanÄ±cÄ± gÃ¶rmeyecek

BAÄLAM:
{context}

VELÄ°NÄ°N SORUSU: {user_msg}

YANITINIZ (samimi, kÄ±sa ve net):"""
    
    # Invoke LLM with single formatted message (Gemini prefers this)
    response = llm.invoke([HumanMessage(content=system_prompt)])
    
    return {"messages": [AIMessage(content=response.content)]}

class ChatSession:
    """LangGraph-based chat session manager."""
    
    def __init__(self, llm: ChatGoogleGenerativeAI, checkpointer: MemorySaver):
        self.llm = llm
        self.checkpointer = checkpointer
        self.graph = self._build_graph()
        self.thread_id = "default"  # Can be changed for multi-user scenarios
    
    def _build_graph(self) -> StateGraph:
        """Build the LangGraph workflow."""
        # Create graph
        workflow = StateGraph(ChatState)
        
        # Add nodes
        workflow.add_node("retrieve", retrieve_node)
        workflow.add_node("llm", lambda state: llm_node(state, self.llm))
        
        # Add edges - simple flow for now
        workflow.add_edge(START, "retrieve")
        workflow.add_edge("retrieve", "llm")
        workflow.add_edge("llm", END)
        
        # Compile with checkpointer
        return workflow.compile(checkpointer=self.checkpointer)
    
    def get_config(self):
        """Get configuration with thread_id."""
        return {"configurable": {"thread_id": self.thread_id}}
    
    def get_state(self) -> dict:
        """Get current state as dict."""
        state = self.graph.get_state(self.get_config())
        if state and state.values:
            # Ensure all keys have defaults
            values = state.values
            return {
                "levels": values.get("levels"),
                "messages": values.get("messages", []),
                "context": values.get("context", "")
            }
        return {"levels": None, "messages": [], "context": ""}
    
    def clear_history(self):
        """Clear conversation history by resetting thread."""
        self.thread_id = f"thread_{os.urandom(8).hex()}"
        print("\nâœ… Sohbet geÃ§miÅŸi temizlendi.")
    
    def set_levels(self, levels: list[str]):
        """Set education levels in state."""
        # Simply update state with new levels
        self.graph.update_state(self.get_config(), {"levels": levels})
        print(f"\nâœ… Kademeler gÃ¼ncellendi: {', '.join([get_level_display_name(l) for l in levels])}")
    
    def chat(self, user_query: str) -> str:
        """Send user message and get response."""
        try:
            # Simply invoke with the new message - let the graph handle state
            # The 'add' operator will automatically append to existing messages
            result = self.graph.invoke(
                {"messages": [HumanMessage(content=user_query)]},
                self.get_config()
            )
            
            # Extract last AI message from result
            if result and "messages" in result:
                for msg in reversed(result["messages"]):
                    if isinstance(msg, AIMessage):
                        response = msg.content
                        
                        # Check for level change tags
                        import re
                        tag_pattern = r'#KADEME_EKLE:(\w+)#'
                        matches = re.findall(tag_pattern, response)
                        
                        if matches:
                            # Extract and add new levels
                            current_state = self.get_state()
                            current_levels = current_state.get("levels", [])
                            
                            for level_to_add in matches:
                                level_to_add = level_to_add.lower()
                                if level_to_add in SUPPORTED_LEVELS and level_to_add not in current_levels:
                                    current_levels.append(level_to_add)
                            
                            # Update state with new levels
                            if current_levels != current_state.get("levels", []):
                                self.graph.update_state(self.get_config(), {"levels": current_levels})
                            
                            # Remove tags from response
                            response = re.sub(tag_pattern, '', response).strip()
                        
                        return response
            
            return "ÃœzgÃ¼nÃ¼m, bir yanÄ±t Ã¼retemedim. LÃ¼tfen sorunuzu farklÄ± ÅŸekilde sormayÄ± deneyin."
        except Exception as e:
            print(f"\nâš ï¸ Hata: {e}")
            import traceback
            traceback.print_exc()
            return f"Bir hata oluÅŸtu: {str(e)}"

def main():
    """Main CLI loop with LangGraph-based chat."""
    try:
        # 1. Initialize LLM and checkpointer
        llm = initialize_chat_model()
        checkpointer = MemorySaver()
        
        # 2. Create session
        session = ChatSession(llm, checkpointer)
        
        # 3. Welcome and select levels
        selected_levels = welcome_and_get_levels()
        session.set_levels(selected_levels)
        
        # 4. Show help
        print("\n" + "="*70)
        print("ğŸ’¬ Sohbet baÅŸladÄ±! ArtÄ±k sorularÄ±nÄ±zÄ± sorabilirsiniz.")
        show_help()
        print("="*70)
        
        # 5. Main chat loop
        while True:
            try:
                user_input = input("\nğŸ‘¤ Siz: ").strip()
                
                if not user_input:
                    continue
                
                user_input_lower = user_input.lower()
                
                if user_input_lower in ["/exit", "/cikis", "exit", "quit"]:
                    print("\nğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere! Ä°yi gÃ¼nler dileriz.")
                    break
                
                elif user_input_lower in ["/help", "/yardim"]:
                    show_help()
                    continue
                
                elif user_input_lower in ["/seviye", "/kademe"]:
                    new_levels = welcome_and_get_levels()
                    session.set_levels(new_levels)
                    continue
                
                elif user_input_lower in ["/temizle", "/clear"]:
                    session.clear_history()
                    continue
                
                # Normal chat
                print("\nğŸ¤– Asistan: ", end="", flush=True)
                response = session.chat(user_input)
                print(response)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Program sonlandÄ±rÄ±ldÄ±. Ä°yi gÃ¼nler!")
                break
            except Exception as inner_e:
                print(f"\nâš ï¸ Bir hata oluÅŸtu: {inner_e}")
                print("LÃ¼tfen tekrar deneyin veya /help yazarak yardÄ±m alÄ±n.")

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Program sonlandÄ±rÄ±ldÄ±.")
    except Exception as e:
        print(f"\nâŒ Beklenmedik bir hata oluÅŸtu: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
