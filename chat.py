"""
Refactored Chat Session - LangGraph Multi-Node Architecture
Production-ready, modular, testable chatbot system
"""

import os
from dotenv import load_dotenv
import traceback

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.checkpoint.memory import InMemorySaver

from workflow import create_workflow
from state_schema import create_initial_state, ChatState
from retriever import SUPPORTED_LEVELS

# --- CONFIGURATION ---
def initialize_chat_model() -> ChatGoogleGenerativeAI:
    """API anahtarÄ±nÄ± yÃ¼kler ve sohbet modelini baÅŸlatÄ±r."""
    load_dotenv()
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        raise ValueError("GOOGLE_API_KEY ortam deÄŸiÅŸkeni bulunamadÄ±. .env dosyasÄ±nÄ± kontrol edin.")
    
    # Model selection: env var or fallback to default
    model_name = os.getenv("GEMINI_MODEL")
    
    return ChatGoogleGenerativeAI(
        model=model_name,
        google_api_key=google_api_key,
        temperature=0.4,  # TutarlÄ± ama doÄŸal yanÄ±tlar iÃ§in
    )


def get_level_display_name(level: str) -> str:
    """Seviye kodunu kullanÄ±cÄ± dostu isme Ã§evirir."""
    mapping = {
        "anaokulu": "Anaokulu",
        "ilkokul": "Ä°lkokul (1-4. SÄ±nÄ±f)",
        "ortaokul": "Ortaokul (5-8. SÄ±nÄ±f)",
        "lise": "Lise (9-12. SÄ±nÄ±f)"
    }
    return mapping.get(level, level)


class ChatSession:
    """
    Refactored Chat Session - LangGraph Multi-Node Architecture
    
    âœ¨ YENÄ° Ã–ZELLÄ°KLER:
    - Intent-based deterministik routing
    - ModÃ¼ler prompt sistemi (role, style, context, output ayrÄ±)
    - LangGraph native memory management (checkpointer)
    - Her node izole ve test edilebilir
    - Sliding window memory (LangGraph manages)
    - Production-ready error handling
    
    âŒ ESKÄ° SÄ°STEM (KALDIRILDI):
    - create_agent (tool-based agent)
    - self.conversation_history (manual memory)
    - Double SystemMessage (Ã§ift prompt sorunu)
    - Tool dispatch belirsizliÄŸi
    """
    
    def __init__(self, llm: ChatGoogleGenerativeAI, checkpointer: InMemorySaver = None, compress_context: bool = False):
        self.llm = llm
        self.checkpointer = checkpointer or InMemorySaver()
        self.levels = None  # SeÃ§ili eÄŸitim kademeleri
        self.thread_id = "default"
        self.compress_context = compress_context  # Context compression control (A/B test iÃ§in - DEFAULT: OFF)
        
        # LangGraph workflow oluÅŸtur
        self.workflow = create_workflow(self.llm, self.checkpointer)
    
    def set_levels(self, levels: list[str]):
        """
        EÄŸitim kademelerini ayarla.
        
        Args:
            levels: SeÃ§ili kademe listesi (Ã¶rn: ["anaokulu", "lise"])
        """
        self.levels = levels
        print(f"\nâœ… Kademe gÃ¼ncellendi: {', '.join(levels)}")
    
    def clear_history(self):
        """Sohbet geÃ§miÅŸini temizle - yeni thread ID oluÅŸtur."""
        self.thread_id = f"thread_{os.urandom(8).hex()}"
        print(f"\nğŸ—‘ï¸  Sohbet geÃ§miÅŸi temizlendi (yeni thread: {self.thread_id})")
    
    def chat(self, user_query: str) -> str:
        """
        KullanÄ±cÄ± mesajÄ±nÄ± iÅŸle ve yanÄ±t dÃ¶ndÃ¼r.
        
        LangGraph Workflow:
        1. Intent Detection â†’ Query classify edilir
        2. Router â†’ Intent'e gÃ¶re doÄŸru node'a yÃ¶nlendirilir
        3. Retrieve/News/Price/Direct â†’ Context hazÄ±rlanÄ±r
        4. Answer â†’ Final LLM yanÄ±tÄ± oluÅŸturulur
        
        Memory:
        - LangGraph checkpointer otomatik manage eder
        - Sliding window (last 10 messages) answer_node iÃ§inde
        - Thread-based conversation persistence
        
        Args:
            user_query: KullanÄ±cÄ±nÄ±n sorusu
        
        Returns:
            Final answer string
        """
        try:
            # Active levels
            active_levels = self.levels if self.levels else list(SUPPORTED_LEVELS)
            
            # Get conversation history from checkpointer
            config = {"configurable": {"thread_id": self.thread_id}}
            
            # Get existing messages from checkpointer (if any)
            try:
                snapshot = self.workflow.get_state(config)
                existing_messages = snapshot.values.get("messages", []) if snapshot else []
            except:
                existing_messages = []
            
            # Add new user message
            messages = existing_messages + [HumanMessage(content=user_query)]
            
            # Create initial state
            initial_state = create_initial_state(
                user_query=user_query,
                active_levels=active_levels,
                messages=messages,
                compress_context=self.compress_context  # A/B test iÃ§in
            )
            
            print(f"\n" + "="*80)
            print(f"ğŸ’¬ [CHAT SESSION] Yeni soru iÅŸleniyor")
            print(f"   Thread ID: {self.thread_id}")
            print(f"   Aktif kademeler: {active_levels}")
            print(f"   Mesaj geÃ§miÅŸi: {len(messages)} mesaj")
            print(f"   ğŸ—œï¸  Context Compression: {'ON' if self.compress_context else 'OFF'}")
            print("="*80)
            
            # Invoke workflow
            result = self.workflow.invoke(initial_state, config)
            
            # Extract final answer
            final_answer = result.get("final_answer", "ÃœzgÃ¼nÃ¼m, bir yanÄ±t Ã¼retemedim.")
            
            print(f"\nâœ… [CHAT SESSION] YanÄ±t hazÄ±r ({len(final_answer)} karakter)")
            print("="*80 + "\n")
            
            return final_answer
            
        except Exception as e:
            print(f"\nâŒ [CHAT SESSION] Hata oluÅŸtu:")
            traceback.print_exc()
            return "ÃœzgÃ¼nÃ¼m, teknik bir sorun oluÅŸtu. LÃ¼tfen tekrar deneyin."


# Test
if __name__ == "__main__":
    """
    Test senaryolarÄ±:
    1. Greeting
    2. Education (FAISS retrieval)
    3. Price (contact info)
    4. Unknown (fallback)
    """
    print("ğŸ¤– Refactored Chat Session Test\n")
    
    llm = initialize_chat_model()
    session = ChatSession(llm)
    
    # Test 1: Greeting
    print("\n" + "ğŸŸ¢ TEST 1: GREETING".center(80, "="))
    session.set_levels(["anaokulu"])
    response1 = session.chat("Merhaba")
    print(f"\nğŸ“ YanÄ±t:\n{response1}\n")
    
    # Test 2: Education
    print("\n" + "ğŸŸ¢ TEST 2: EDUCATION (FAISS)".center(80, "="))
    response2 = session.chat("Anaokulunda Ä°ngilizce eÄŸitimi nasÄ±l?")
    print(f"\nğŸ“ YanÄ±t:\n{response2}\n")
    
    # Test 3: Price
    print("\n" + "ğŸŸ¢ TEST 3: PRICE".center(80, "="))
    response3 = session.chat("Ãœcretler ne kadar?")
    print(f"\nğŸ“ YanÄ±t:\n{response3}\n")
    
    # Test 4: Unknown
    print("\n" + "ğŸŸ¢ TEST 4: UNKNOWN".center(80, "="))
    response4 = session.chat("Hava durumu nasÄ±l?")
    print(f"\nğŸ“ YanÄ±t:\n{response4}\n")
    
    # Test 5: Level change
    print("\n" + "ğŸŸ¢ TEST 5: LEVEL CHANGE".center(80, "="))
    session.set_levels(["lise"])
    response5 = session.chat("Ä°ngilizce eÄŸitimi nasÄ±l?")
    print(f"\nğŸ“ YanÄ±t:\n{response5}\n")
    
    print("\n" + "âœ… TÃœM TESTLER TAMAMLANDI".center(80, "=") + "\n")
